{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e60e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "from generation.utils import GenerationMixin\n",
    "from tone_utils import find_tone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d230f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto model won't work here, you will need to change the class name for a new architecture\n",
    "# Auto model use some black magic fuckery to determine the correct class name which will ignore our custom mixin\n",
    "class CustomLlamaForCausalLM(GenerationMixin, LlamaForCausalLM):\n",
    "    pass\n",
    "\n",
    "model_name = 'bkai-foundation-models/vietnamese-llama2-7b-40GB'\n",
    "token = \"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,\n",
    "                                          token=token)\n",
    "\n",
    "model = CustomLlamaForCausalLM.from_pretrained(model_name, \n",
    "                                                # load_in_8bit=True,\n",
    "                                                token=token,\n",
    "                                                device_map={'': 0},\n",
    "                                                torch_dtype=torch.bfloat16)\n",
    "model = PeftModel.from_pretrained(model, \"suicaokhoailang/bkllama2-poem-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7bd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhymes = json.load(open(\"./data/rhymables.json\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Chỉ dùng các âm tiết xác định được vần điệu\n",
    "allowed_ids = [x['id'] for x in rhymes.values()] + tokenizer.encode(\"\\n\")[-1:]\n",
    "all_ids = np.arange(len(tokenizer.get_vocab()))\n",
    "not_allowed_ids = set(all_ids) - set(allowed_ids)\n",
    "not_allowed_ids = [[x] for x in not_allowed_ids]\n",
    "\n",
    "# Từ điển vần\n",
    "rhymable_dict = dict([(val['id'], set(val[\"rhymes_with_ids\"])) for key, val in rhymes.items()])\n",
    "# Các âm bằng trắc\n",
    "even_ids = [val['id'] for key, val in rhymes.items() if find_tone(key) < 2]\n",
    "uneven_ids = [val['id'] for key, val in rhymes.items() if find_tone(key) >= 2]\n",
    "# Các âm huyền, ngang\n",
    "unmarked_ids = [val['id'] for key, val in rhymes.items() if find_tone(key) == 0]\n",
    "grave_ids = [val['id'] for key, val in rhymes.items() if find_tone(key) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db9e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(text):\n",
    "    return f\"\"\" \n",
    "Viết bài thơ có nội dung: {text}\n",
    "### Trả lời:\n",
    "\"\"\"[1:]\n",
    "\n",
    "def generate(text, max_pairs=5):\n",
    "    text = generate_prompt(text)\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "    min_length = 16 * 2 + len(input_ids[0])\n",
    "    max_length = 16 * max(3,max_pairs) + len(input_ids[0])  # + 40\n",
    "    sample_outputs = model.generate(input_ids=input_ids, pad_token_id=tokenizer.eos_token_id,\n",
    "                                    do_sample=False,\n",
    "                                    max_length=max_length,\n",
    "                                    min_length=min_length,\n",
    "                                    num_beams=5,\n",
    "                                    no_repeat_ngram_size=3,\n",
    "                                    num_return_sequences=1,\n",
    "                                    eos_token_id=[-1],\n",
    "                                    bad_words_ids=not_allowed_ids,\n",
    "                                    newline_id=tokenizer.encode(\"\\n\")[-1:],\n",
    "                                    repetition_penalty=1.5,\n",
    "                                    temperature=1.5,\n",
    "                                    all_ids=all_ids,\n",
    "                                    rhymable_dict=rhymable_dict,\n",
    "                                    grave_ids=grave_ids,\n",
    "                                    unmarked_ids=unmarked_ids,\n",
    "                                    even_ids=even_ids,\n",
    "                                    uneven_ids=uneven_ids,\n",
    "                                    generate_6_8=True)\n",
    "\n",
    "    return tokenizer.decode(sample_outputs[0].tolist(), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55ab3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<s> \n",
      "Viết bài thơ có nội dung: ăn phở\n",
      "### Trả lời:\n",
      "ăn gì ngon miệng không chê\n",
      "chỉ chê người bán dở nghề thôi nha\n",
      "ăn rồi lại thấy nhớ nhà\n",
      "ăn thêm một bát nữa nha nó về\n",
      "ăn hoài vẫn thấy đói ghê\n",
      "ăn bao nhiêu vẫn chưa về nhà đâu\n",
      "ăn nhiều lại thấy buồn rầu\n",
      "ăn càng nhiều lại càng sầu khổ đau\n",
      "ăn cho hết sạch còn đâu\n",
      "cũng đành bỏ lại ở sau quán này\n"
     ]
    }
   ],
   "source": [
    "text = 'ăn phở'\n",
    "print(generate(text,max_pairs=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0c1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
